import os
import torch
if hasattr(torch, '_dynamo'):
    torch._dynamo.disable()
    print("å·²ç¦ç”¨ torch._dynamo")
from llava_pythia.conversation import conv_templates, SeparatorStyle
from llava_pythia.model.builder import load_pretrained_model
from llava_pythia.mm_utils import tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria
import torch
from torchvision import transforms
import cv2
from copy import deepcopy
from itertools import repeat
from llava_pythia.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
import numpy as np
import time
import signal
import sys
from aloha_scripts.constants import FPS
from data_utils.datasets import set_seed
from llava_pythia.model import *
from einops import rearrange
import torch_utils as TorchUtils
import matplotlib.pyplot as plt
from collections import deque
# ========== ROS ç›¸å…³å¯¼å…¥ ==========
import rospy
from sensor_msgs.msg import Image, JointState
from geometry_msgs.msg import PoseStamped
from std_msgs.msg import Float64
from cv_bridge import CvBridge
# =================================

# ========== Franka Panda å…³èŠ‚é™åˆ¶ ==========
FRANKA_JOINT_LIMITS = {
    'min': [-2.8973, -1.7628, -2.8973, -3.0718, -2.8973, -0.0175, -2.8973],
    'max': [2.8973, 1.7628, 2.8973, -0.0698, 2.8973, 3.7525, 2.8973]
}
# ========================================

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨deploy_envå®ä¾‹
global global_deploy_env
global_deploy_env = None

def signal_handler(sig, frame):
    """ä¿¡å·å¤„ç†å™¨ï¼Œç”¨äºå®‰å…¨å…³é—­ç¨‹åº"""
    print('æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨å…³é—­...')
    if global_deploy_env is not None:
        print('æ‰§è¡Œç´§æ€¥åœæ­¢...')
        global_deploy_env.emergency_stop()
    # ç¡®ä¿ROSèŠ‚ç‚¹æ­£ç¡®å…³é—­
    if not rospy.is_shutdown():
        rospy.signal_shutdown("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    print('ç¨‹åºå·²å®‰å…¨å…³é—­')
    sys.exit(0)
def get_obs(obs, stats):
    images, robot_state = obs
    normalized_state = (robot_state - stats['qpos_mean']) / stats['qpos_std']
    return images, normalized_state
def ensure_quaternion_continuity(current_quat, last_quat):
    """
    ç¡®ä¿å››å…ƒæ•°è¿ç»­æ€§ï¼Œé¿å…180åº¦ç¿»è½¬

    Args:
        current_quat: å½“å‰å››å…ƒæ•° [x, y, z, w]
        last_quat: ä¸Šä¸€ä¸ªå››å…ƒæ•° [x, y, z, w]

    Returns:
        corrected_quat: ä¿®æ­£åçš„å››å…ƒæ•°
    """
    if last_quat is None:
        return current_quat

    # è®¡ç®—ç‚¹ç§¯
    dot_product = np.dot(current_quat, last_quat)

    # å¦‚æœç‚¹ç§¯ä¸ºè´Ÿï¼Œè¯´æ˜å››å…ƒæ•°ç¬¦å·ä¸ä¸€è‡´
    if dot_product < 0:
        # å–åå½“å‰å››å…ƒæ•°ä»¥ä¿æŒè¿ç»­æ€§
        return -current_quat

    return current_quat

def convert_actions(pred_action, task_type="pick_up_bowl", last_action=None, smoothing_factor=0.3, current_ee_pos=None):
    """
    æ”¹è¿›çš„åŠ¨ä½œè½¬æ¢å‡½æ•° - å°†actionè§£é‡Šä¸ºç›¸å¯¹ä½ç§»è€Œä¸æ˜¯ç»å¯¹åæ ‡

    Args:
        pred_action: åŸå§‹é¢„æµ‹åŠ¨ä½œ (10ç»´)
        task_type: ä»»åŠ¡ç±»å‹
        last_action: ä¸Šä¸€ä¸ªåŠ¨ä½œï¼Œç”¨äºå¹³æ»‘ (7ç»´: xyz + quat)
        smoothing_factor: å¹³æ»‘å› å­ (0-1)ï¼Œ0=æ— å¹³æ»‘ï¼Œ1=å®Œå…¨ä½¿ç”¨ä¸Šä¸€ä¸ªåŠ¨ä½œ
        current_ee_pos: å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½ç½® (3ç»´: xyz) - å¿…éœ€å‚æ•°
    """
    # 1. åŸºæœ¬æ£€æŸ¥
    if np.any(np.isnan(pred_action)) or np.any(np.isinf(pred_action)):
        print(f"è­¦å‘Š: æ£€æµ‹åˆ°NaNæˆ–Infå€¼åœ¨é¢„æµ‹åŠ¨ä½œä¸­")
        # è¿”å›é›¶ä½ç§»è€Œä¸æ˜¯å›ºå®šä½ç½®
        safe_action = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])
        print(f"ä½¿ç”¨å®‰å…¨åŠ¨ä½œ(é›¶ä½ç§»): {safe_action}")
        return safe_action

    # æ£€æŸ¥åŠ¨ä½œç»´åº¦
    if len(pred_action) < 10:
        print(f"è­¦å‘Š: åŠ¨ä½œç»´åº¦ä¸è¶³: {len(pred_action)}ï¼ŒæœŸæœ›è‡³å°‘10ç»´")
        safe_action = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])
        return safe_action

    # æ£€æŸ¥æ˜¯å¦æä¾›äº†å½“å‰ä½ç½®
    if current_ee_pos is None:
        print("è­¦å‘Š: æœªæä¾›current_ee_posï¼Œä½¿ç”¨é»˜è®¤ä½ç½®")
        current_ee_pos = np.array([0.3, 0.0, 0.3])

    # 2. æå–åˆ†é‡
    # âœ… å…³é”®ä¿®æ”¹: pred_action[:3] ç°åœ¨è¢«è§£é‡Šä¸ºç›¸å¯¹ä½ç§»(delta)è€Œä¸æ˜¯ç»å¯¹åæ ‡
    delta_xyz = pred_action[:3].copy()
    cur_rot6d = pred_action[3:9].copy()
    cur_gripper = pred_action[9]

    # 3. åˆ†æåŸå§‹è¾“å‡º
    print(f"åŸå§‹ä½ç§»è¾“å‡º(delta): {delta_xyz}")
    print(f"åŸå§‹ä½ç§»å¹…åº¦: {np.linalg.norm(delta_xyz):.3f}")
    print(f"å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®: {current_ee_pos}")

    # 4. âœ… é™åˆ¶ç›¸å¯¹ä½ç§»çš„å¤§å°ï¼ˆé˜²æ­¢å•æ­¥ç§»åŠ¨è¿‡å¤§ï¼‰
    # æ¯æ­¥æœ€å¤§ä½ç§»é™åˆ¶ä¸º 5cm
    max_delta = 0.05  # 5cm
    delta_norm = np.linalg.norm(delta_xyz)
    if delta_norm > max_delta:
        print(f"ä½ç§»è¿‡å¤§ ({delta_norm:.3f}m)ï¼Œé™åˆ¶åˆ° {max_delta}m")
        delta_xyz = delta_xyz / delta_norm * max_delta
        print(f"é™åˆ¶åçš„ä½ç§»: {delta_xyz}")

    # 5. âœ… è®¡ç®—ç›®æ ‡ä½ç½® = å½“å‰ä½ç½® + ç›¸å¯¹ä½ç§»
    target_xyz = current_ee_pos + delta_xyz
    print(f"è®¡ç®—ç›®æ ‡ä½ç½®: {current_ee_pos} + {delta_xyz} = {target_xyz}")

    # 6. ç¡®ä¿ç›®æ ‡ä½ç½®åœ¨å®‰å…¨å·¥ä½œç©ºé—´å†…ï¼ˆç»å¯¹åæ ‡é™åˆ¶ï¼‰
    # Franka Pandaçš„å®‰å…¨å·¥ä½œç©ºé—´
    safe_x_range = [0.1, 0.6]    # XèŒƒå›´ï¼ˆé˜²æ­¢æ’åˆ°åŸºåº§ï¼‰
    safe_y_range = [-0.4, 0.4]   # YèŒƒå›´
    safe_z_range = [0.05, 0.7]   # ZèŒƒå›´ï¼ˆé˜²æ­¢æ’åˆ°æ¡Œé¢ï¼‰

    # è£å‰ªåˆ°å®‰å…¨èŒƒå›´
    for i, (safe_min, safe_max) in enumerate([(safe_x_range[0], safe_x_range[1]),
                                              (safe_y_range[0], safe_y_range[1]),
                                              (safe_z_range[0], safe_z_range[1])]):
        if target_xyz[i] < safe_min:
            print(f"è½´{i}ä½äºä¸‹ç•Œ {safe_min:.3f}ï¼Œå½“å‰å€¼: {target_xyz[i]:.3f}ï¼Œå·²ä¿®æ­£ä¸º: {safe_min:.3f}")
            target_xyz[i] = safe_min
        elif target_xyz[i] > safe_max:
            print(f"è½´{i}é«˜äºä¸Šç•Œ {safe_max:.3f}ï¼Œå½“å‰å€¼: {target_xyz[i]:.3f}ï¼Œå·²ä¿®æ­£ä¸º: {safe_max:.3f}")
            target_xyz[i] = safe_max

    # 7. åº”ç”¨å¹³æ»‘ï¼ˆå¦‚æœæä¾›äº†ä¸Šä¸€ä¸ªåŠ¨ä½œï¼‰
    if last_action is not None and len(last_action) >= 3 and smoothing_factor > 0:
        last_xyz = last_action[:3]
        target_xyz = smoothing_factor * last_xyz + (1 - smoothing_factor) * target_xyz
        print(f"åº”ç”¨å¹³æ»‘: æ–°ç›®æ ‡ä½ç½® = {target_xyz}")

    # 7. æ—‹è½¬å¤„ç†
    try:
        # 7.1 é¦–å…ˆå½’ä¸€åŒ–æ—‹è½¬6Dè¡¨ç¤ºï¼Œé¿å…å¤§å¹…åº¦æ—‹è½¬
        rot6d_norm = np.linalg.norm(cur_rot6d)
        if rot6d_norm > 0:
            # å¦‚æœèŒƒæ•°å¤ªå¤§ï¼Œå½’ä¸€åŒ–åˆ°åˆç†èŒƒå›´
            if rot6d_norm > 2.0:
                print(f"æ—‹è½¬6DèŒƒæ•°è¿‡å¤§ ({rot6d_norm:.3f})ï¼Œè¿›è¡Œå½’ä¸€åŒ–")
                cur_rot6d = cur_rot6d / rot6d_norm
                rot6d_norm = 1.0
            elif rot6d_norm < 0.1:
                # å¦‚æœèŒƒæ•°å¤ªå°ï¼Œä½¿ç”¨é»˜è®¤æ—‹è½¬ï¼ˆå•ä½çŸ©é˜µï¼‰
                print(f"æ—‹è½¬6DèŒƒæ•°è¿‡å° ({rot6d_norm:.3f})ï¼Œä½¿ç”¨é»˜è®¤æ—‹è½¬")
                cur_rot6d = np.array([1.0, 0.0, 0.0, 0.0, 1.0, 0.0])
                rot6d_norm = np.sqrt(2.0)
        else:
            # é›¶å‘é‡ï¼Œä½¿ç”¨é»˜è®¤æ—‹è½¬
            print("æ—‹è½¬6Dä¸ºé›¶å‘é‡ï¼Œä½¿ç”¨é»˜è®¤æ—‹è½¬")
            cur_rot6d = np.array([1.0, 0.0, 0.0, 0.0, 1.0, 0.0])
            rot6d_norm = np.sqrt(2.0)

        print(f"å½’ä¸€åŒ–åæ—‹è½¬6DèŒƒæ•°: {rot6d_norm:.3f}")

        # 7.2 ç›´æ¥ä»æ—‹è½¬6Dè½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µï¼Œå†è½¬æ¢ä¸ºå››å…ƒæ•°
        cur_rot6d_tensor = torch.from_numpy(cur_rot6d).unsqueeze(0).float()
        # ç›´æ¥è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        rot_matrix = TorchUtils.rotation_6d_to_matrix(cur_rot6d_tensor).squeeze().numpy()

        # 7.3 ä»æ—‹è½¬çŸ©é˜µç›´æ¥è½¬æ¢ä¸ºå››å…ƒæ•°
        from scipy.spatial.transform import Rotation as R
        r = R.from_matrix(rot_matrix)
        quat = r.as_quat()

        print(f"åŸå§‹å››å…ƒæ•°: {quat}")

        # 7.4 å››å…ƒæ•°ç¨³å®šæ€§å¢å¼º
        # ç¡®ä¿å››å…ƒæ•°æ•°å€¼ç¨³å®šæ€§å’Œä¸€è‡´æ€§
        quat_norm = np.linalg.norm(quat)
        if quat_norm > 0:
            quat = quat / quat_norm  # å½’ä¸€åŒ–
        else:
            # å¦‚æœå››å…ƒæ•°ä¸ºé›¶å‘é‡ï¼Œä½¿ç”¨å•ä½å››å…ƒæ•°
            quat = np.array([0.0, 0.0, 0.0, 1.0])
            print("è­¦å‘Š: å››å…ƒæ•°ä¸ºé›¶å‘é‡ï¼Œä½¿ç”¨å•ä½å››å…ƒæ•°")

        # 7.5 åº”ç”¨æ—‹è½¬å¹³æ»‘ï¼ˆå¦‚æœæä¾›äº†ä¸Šä¸€ä¸ªåŠ¨ä½œï¼‰
        if last_action is not None and len(last_action) >= 7:
            try:
                # æå–ä¸Šä¸€ä¸ªåŠ¨ä½œçš„å››å…ƒæ•°
                last_quat = last_action[3:]

                # æ£€æŸ¥å››å…ƒæ•°æ˜¯å¦æœ‰æ•ˆ
                last_norm = np.linalg.norm(last_quat)
                if last_norm > 0:
                    last_quat = last_quat / last_norm  # å½’ä¸€åŒ–

                    # ä½¿ç”¨çƒé¢çº¿æ€§æ’å€¼(Slerp)è¿›è¡Œæ—‹è½¬å¹³æ»‘
                    rotation_smoothing = smoothing_factor * 0.3  # æ—‹è½¬å¹³æ»‘æ¯”ä½ç½®å¹³æ»‘å¼±
                    if rotation_smoothing > 0:
                        try:
                            last_r = R.from_quat(last_quat)
                            key_rots = R.concatenate([last_r, r])
                            key_times = [0, 1]
                            from scipy.spatial.transform import Slerp
                            slerp = Slerp(key_times, key_rots)
                            smoothed_r = slerp([rotation_smoothing])[0]
                            new_quat = smoothed_r.as_quat()

                            # ç¡®ä¿æ–°å››å…ƒæ•°ä¸æ—§å››å…ƒæ•°æ–¹å‘ä¸€è‡´
                            dot_product = np.dot(new_quat, last_quat)
                            if dot_product < 0:
                                new_quat = -new_quat  # å–åä»¥ä¿æŒè¿ç»­æ€§

                            quat = new_quat
                            print(f"åº”ç”¨æ—‹è½¬å¹³æ»‘ (Slerp)")
                        except Exception as slerp_error:
                            print(f"Slerpå¹³æ»‘é”™è¯¯: {slerp_error}, ä½¿ç”¨çº¿æ€§æ’å€¼")
                            # ä½¿ç”¨ç®€å•çš„çº¿æ€§æ’å€¼ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
                            quat = (1 - rotation_smoothing) * quat + rotation_smoothing * last_quat
                            # å½’ä¸€åŒ–ç»“æœ
                            quat_norm = np.linalg.norm(quat)
                            if quat_norm > 0:
                                quat = quat / quat_norm
                else:
                    print("ä¸Šä¸€ä¸ªåŠ¨ä½œçš„å››å…ƒæ•°æ— æ•ˆï¼Œè·³è¿‡æ—‹è½¬å¹³æ»‘")
            except Exception as e:
                print(f"æ—‹è½¬å¹³æ»‘é”™è¯¯: {e}, ä½¿ç”¨æœªå¹³æ»‘çš„å››å…ƒæ•°")

        # ç¡®ä¿å››å…ƒæ•°å½’ä¸€åŒ–
        quat_norm = np.linalg.norm(quat)
        if abs(quat_norm - 1.0) > 0.01:
            quat = quat / quat_norm
            print(f"å››å…ƒæ•°å·²å½’ä¸€åŒ–: èŒƒæ•°ä» {quat_norm:.3f} è°ƒæ•´åˆ° 1.0")

        # å››å…ƒæ•°ç¬¦å·å¤„ç†ï¼šé¿å…180åº¦æ—‹è½¬æ­§ä¹‰
        # ç­–ç•¥ï¼šä¼˜å…ˆä¿è¯è¿ç»­æ€§ï¼Œç„¶åå°½é‡ä¿è¯wåˆ†é‡ä¸ºæ­£
        quat_modified = False

        # 1. ä½¿ç”¨ä¸“é—¨çš„å‡½æ•°ç¡®ä¿å››å…ƒæ•°è¿ç»­æ€§
        if last_action is not None and len(last_action) >= 7:
            last_quat = last_action[3:]
            original_quat = quat.copy()
            quat = ensure_quaternion_continuity(quat, last_quat)

            if not np.allclose(original_quat, quat):
                quat_modified = True
                print("å››å…ƒæ•°è¿ç»­æ€§è°ƒæ•´: å·²ç¡®ä¿ç¬¦å·ä¸€è‡´")

        # 2. åœ¨ä¿è¯è¿ç»­æ€§çš„å‰æä¸‹ï¼Œå°½é‡ä½¿wåˆ†é‡ä¸ºæ­£
        # æ³¨æ„ï¼šå¦‚æœå–åä¼šç ´åè¿ç»­æ€§ï¼Œåˆ™ä¿æŒåŸæ ·
        if quat[3] < 0:
            # æ£€æŸ¥å–åæ˜¯å¦ä¼šå½±å“è¿ç»­æ€§
            should_flip = True
            if last_action is not None and len(last_action) >= 7:
                last_quat = last_action[3:]
                dot_if_flipped = np.dot(-quat, last_quat)
                if dot_if_flipped < 0:
                    # å–åä¼šä½¿ç‚¹ç§¯å˜è´Ÿï¼Œç ´åè¿ç»­æ€§ï¼Œæ‰€ä»¥ä¸å–å
                    should_flip = False
                    print(f"ä¿æŒwåˆ†é‡ä¸ºè´Ÿä»¥é¿å…ç ´åè¿ç»­æ€§ (å–ååç‚¹ç§¯: {dot_if_flipped:.3f})")

            if should_flip:
                quat = -quat
                quat_modified = True
                print("å››å…ƒæ•°ç¬¦å·è§„èŒƒåŒ–: wåˆ†é‡ä¸ºè´Ÿï¼Œå·²å–å")

        # 3. é¢å¤–çš„180åº¦ç¿»è½¬æ£€æµ‹å’Œä¿®æ­£
        # æ£€æŸ¥æ˜¯å¦å‘ç”Ÿäº†æ¥è¿‘180åº¦çš„ç¿»è½¬
        if last_action is not None and len(last_action) >= 7:
            last_quat = last_action[3:]
            # è®¡ç®—ä¸¤ä¸ªå››å…ƒæ•°ä¹‹é—´çš„è§’åº¦å·®
            dot_product = np.abs(np.dot(quat, last_quat))

            # å¦‚æœç‚¹ç§¯æ¥è¿‘0ï¼Œè¯´æ˜ä¸¤ä¸ªå››å…ƒæ•°æ¥è¿‘æ­£äº¤ï¼Œå¯èƒ½å‘ç”Ÿ180åº¦ç¿»è½¬
            if dot_product < 0.1:  # é˜ˆå€¼å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                print(f"æ£€æµ‹åˆ°å¯èƒ½çš„180åº¦ç¿»è½¬ï¼Œç‚¹ç§¯: {dot_product:.3f}")

                # å°è¯•å¤šç§ä¿®æ­£æ–¹æ³•ï¼Œé€‰æ‹©æœ€åˆé€‚çš„
                candidates = [
                    quat,           # åŸå§‹å››å…ƒæ•°
                    -quat,          # å–å
                ]

                best_candidate = quat
                best_dot = dot_product

                for candidate in candidates:
                    candidate_dot = np.abs(np.dot(candidate, last_quat))
                    if candidate_dot > best_dot:
                        best_dot = candidate_dot
                        best_candidate = candidate

                if not np.allclose(best_candidate, quat):
                    quat = best_candidate
                    quat_modified = True
                    print(f"å·²ä¿®æ­£180åº¦ç¿»è½¬ï¼Œæ–°çš„ç‚¹ç§¯: {best_dot:.3f}")

        if quat_modified:
            # é‡æ–°å½’ä¸€åŒ–ï¼ˆå–åä¸å½±å“èŒƒæ•°ï¼Œä½†ä¸ºäº†å®‰å…¨ï¼‰
            quat_norm = np.linalg.norm(quat)
            if abs(quat_norm - 1.0) > 0.01:
                quat = quat / quat_norm

        # 8. å§¿æ€åˆç†æ€§æ£€æŸ¥å’Œä¿®æ­£ï¼ˆé’ˆå¯¹æŠ“å–ä»»åŠ¡ï¼‰
        # æ£€æŸ¥æ˜¯å¦ä¸ºæŠ“å–ç¢—çš„ä»»åŠ¡ï¼Œå¦‚æœæ˜¯åˆ™ç¡®ä¿æœ«ç«¯æ‰§è¡Œå™¨å‘ä¸‹æŒ‡å‘
        if "pick" in task_type.lower() or "bowl" in task_type.lower():
            print("æ£€æµ‹åˆ°æŠ“å–ä»»åŠ¡ï¼Œæ£€æŸ¥å§¿æ€åˆç†æ€§...")

            # å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ¬§æ‹‰è§’è¿›è¡Œåˆ†æ
            r_current = R.from_quat(quat)
            euler_current = r_current.as_euler('xyz', degrees=True)

            print(f"å½“å‰æ¬§æ‹‰è§’: roll={euler_current[0]:.2f}Â°, pitch={euler_current[1]:.2f}Â°, yaw={euler_current[2]:.2f}Â°")

            # æ£€æŸ¥Zè½´æ–¹å‘æ˜¯å¦å‘ä¸‹ï¼ˆé€‚åˆæŠ“å–ï¼‰
            z_direction = r_current.apply([0, 0, 1])  # åº”ç”¨æ—‹è½¬åˆ°åŸå§‹Zè½´
            print(f"å½“å‰Zè½´æ–¹å‘: [{z_direction[0]:.3f}, {z_direction[1]:.3f}, {z_direction[2]:.3f}]")

            # å¦‚æœZè½´ä¸æ˜¯å‘ä¸‹æŒ‡å‘ï¼ˆZåˆ†é‡åº”è¯¥æ¥è¿‘-1ï¼‰
            if z_direction[2] > -0.5:  # å¦‚æœä¸æ˜¯æ˜æ˜¾å‘ä¸‹æŒ‡å‘
                print(f"å§¿æ€ä¸åˆç†: Zè½´æ–¹å‘ {z_direction[2]:.3f} ä¸é€‚åˆæŠ“å–ä»»åŠ¡")

                # ä½¿ç”¨ç¡®å®šçš„å‘ä¸‹æŒ‡å‘å§¿æ€ [0, 1, 0, 0] (ç»•Yè½´180åº¦)
                # è¿™ä¸ªå§¿æ€ç¡®ä¿æœ«ç«¯æ‰§è¡Œå™¨Zè½´å‘ä¸‹æŒ‡å‘[0, 0, -1]ï¼Œé¿å…å³åæ–¹æ—‹è½¬é—®é¢˜
                print("æ£€æµ‹åˆ°å§¿æ€ä¸åˆç†ï¼Œå¼ºåˆ¶è®¾ç½®ä¸ºæ ‡å‡†å‘ä¸‹æŒ‡å‘å§¿æ€")
                quat = np.array([0.0, 1.0, 0.0, 0.0])

                # éªŒè¯ä¿®æ­£æ•ˆæœ
                r_fixed = R.from_quat(quat)
                fixed_z_direction = r_fixed.apply([0, 0, 1])
                fixed_x_direction = r_fixed.apply([1, 0, 0])
                fixed_y_direction = r_fixed.apply([0, 1, 0])

                print(f"ä¿®æ­£åå››å…ƒæ•°: {quat}")
                print(f"ä¿®æ­£åZè½´æ–¹å‘: [{fixed_z_direction[0]:.3f}, {fixed_z_direction[1]:.3f}, {fixed_z_direction[2]:.3f}] (åº”ä¸º[0,0,-1])")
                print(f"ä¿®æ­£åXè½´æ–¹å‘: [{fixed_x_direction[0]:.3f}, {fixed_x_direction[1]:.3f}, {fixed_x_direction[2]:.3f}] (åº”ä¸º[-1,0,0])")
                print(f"ä¿®æ­£åYè½´æ–¹å‘: [{fixed_y_direction[0]:.3f}, {fixed_y_direction[1]:.3f}, {fixed_y_direction[2]:.3f}] (åº”ä¸º[0,1,0])")
                print("âœ… ä¿®æ­£å®Œæˆï¼Œæœ«ç«¯æ‰§è¡Œå™¨ç°åœ¨åº”è¯¥å‘ä¸‹æŒ‡å‘")

        # 9. å¤¹çˆªå¤„ç†
        # ä½¿ç”¨sigmoidå‡½æ•°å°†å¤¹çˆªå€¼æ˜ å°„åˆ°[0,1]ï¼Œæ›´å¹³æ»‘
        gripper_value = 1.0 / (1.0 + np.exp(-cur_gripper))
        print(f"åŸå§‹å¤¹çˆªå€¼: {cur_gripper:.3f}, sigmoidå¤„ç†å: {gripper_value:.3f}")

        # 10. ç»„åˆæœ€ç»ˆåŠ¨ä½œ
        # å°†å¤¹çˆªå€¼è½¬æ¢ä¸ºç‰©ç†å•ä½ï¼ˆç±³ï¼‰ï¼ŒFrankaå¤¹çˆªæœ€å¤§å¼€åˆè·ç¦»çº¦ä¸º0.08m
        gripper_width = gripper_value * 0.08
        # âœ… ä½¿ç”¨è®¡ç®—åçš„ç›®æ ‡ä½ç½®è€Œä¸æ˜¯åŸå§‹çš„cur_xyz
        pose_action = np.concatenate((target_xyz, quat, [gripper_width]))

        print(f"æ”¹è¿›è½¬æ¢ç»“æœ(ç›¸å¯¹ä½ç§»æ¨¡å¼):")
        print(f"  å½“å‰ä½ç½®: {current_ee_pos}")
        print(f"  ç›¸å¯¹ä½ç§»: {delta_xyz}")
        print(f"  ç›®æ ‡ä½ç½®: {target_xyz}")
        print(f"  å››å…ƒæ•°: {quat}")
        print(f"  å››å…ƒæ•°èŒƒæ•°: {np.linalg.norm(quat):.3f}")
        print(f"  å¤¹çˆªå€¼: {gripper_value:.3f}")
        print(f"  å¤¹çˆªå®½åº¦: {gripper_width:.3f}m")
        print(f"  åŠ¨ä½œç»´åº¦: {len(pose_action)}, åŠ¨ä½œå†…å®¹: {pose_action}")

        # 11. æœ€ç»ˆå®‰å…¨æ£€æŸ¥
        # ç¡®ä¿ä½ç½®åœ¨ç»å¯¹å®‰å…¨èŒƒå›´å†…
        pose_action[0] = np.clip(pose_action[0], 0.1, 0.6)   # Xè½´
        pose_action[1] = np.clip(pose_action[1], -0.4, 0.4)  # Yè½´
        pose_action[2] = np.clip(pose_action[2], 0.05, 0.7)  # Zè½´

        # ç¡®ä¿å››å…ƒæ•°æœ‰æ•ˆ
        if len(pose_action) >= 7:
            quat_norm = np.linalg.norm(pose_action[3:7])
            if quat_norm > 0:
                pose_action[3:7] = pose_action[3:7] / quat_norm
            else:
                pose_action[3:7] = np.array([0.0, 0.0, 0.0, 1.0])

        # ç¡®ä¿å¤¹çˆªå€¼åœ¨åˆç†èŒƒå›´å†…
        # æ³¨æ„: åŠ¨ä½œæ ¼å¼ä¸º [x, y, z, rot_6d(6ç»´), gripper(1ç»´)] = 10ç»´
        # å¤¹çˆªåœ¨ç´¢å¼•9 (ç¬¬10ç»´)
        if len(pose_action) >= 10:
            pose_action[9] = np.clip(pose_action[9], 0.0, 0.08)

        return pose_action

    except Exception as e:
        print(f"æ—‹è½¬è½¬æ¢é”™è¯¯: {e}")
        safe_action = np.array([0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 1.0])
        return safe_action
class llava_pythia_act_policy:
    def __init__(self, policy_config, data_args=None):
        super().__init__()
        self.load_policy(policy_config)
        self.data_args = data_args
    def load_policy(self, policy_config):
        # 1. ä¿å­˜ policy_config
        self.policy_config = policy_config
        from transformers import AutoTokenizer, GPTNeoXTokenizerFast, AutoConfig
        from llava_pythia.model import LlavaPythiaForCausalLM
        from peft import PeftModel
        import os
        import torch
        from torch.nn.functional import interpolate
        model_base = policy_config["model_base"]
        model_path = policy_config["model_path"]
        print("æ­£åœ¨åŠ è½½åŸºç¡€æ¨¡å‹...")
        # 2. åŠ è½½ tokenizer
        try:
            self.tokenizer = GPTNeoXTokenizerFast.from_pretrained(model_base)
        except:
            self.tokenizer = AutoTokenizer.from_pretrained(model_base, use_fast=False)
        self.tokenizer.pad_token = self.tokenizer.eos_token
        # 3. åŠ è½½åŸºç¡€æ¨¡å‹
        base_model = LlavaPythiaForCausalLM.from_pretrained(
            model_base,
            torch_dtype=torch.float32,
            low_cpu_mem_usage=False,
            device_map=None,
            trust_remote_code=True
        ).cpu()
        print("æ­£åœ¨åŠ è½½ LoRA æƒé‡...")
        self.policy = PeftModel.from_pretrained(base_model, model_path, is_trainable=False)
        self.policy = self.policy.merge_and_unload()
        self.policy = self.policy.cuda()
        # 4. ä¿®å¤ä½ç½®ç¼–ç ï¼ˆ320x320ï¼‰
        def interpolate_pos_encoding(vision_tower, image_size=320, patch_size=14):
            vision_model = vision_tower.vision_model
            old_pos_embed = vision_model.embeddings.position_embedding.weight.data
            cls_pos_embed = old_pos_embed[0:1]
            patch_pos_embed = old_pos_embed[1:]
            h = w = image_size // patch_size
            new_hw = h * w
            embed_dim = patch_pos_embed.shape[1]
            patch_pos_embed = patch_pos_embed.transpose(0, 1).view(1, embed_dim, 24, 24)
            new_patch_pos_embed = interpolate(
                patch_pos_embed, size=(h, w), mode='bicubic', align_corners=False
            )
            new_patch_pos_embed = new_patch_pos_embed.view(embed_dim, new_hw).transpose(0, 1)
            new_pos_embed = torch.cat([cls_pos_embed, new_patch_pos_embed], dim=0)
            vision_model.embeddings.position_embedding = torch.nn.Embedding.from_pretrained(new_pos_embed, freeze=False)
            vision_model.embeddings.position_ids = torch.arange(new_pos_embed.shape[0]).expand((1, -1)).cuda()
            print(f"ä½ç½®ç¼–ç å·²ä» 577 â†’ {new_pos_embed.shape[0]}ï¼ˆé€‚é… {image_size}x{image_size}ï¼‰")
        if hasattr(self.policy, 'get_vision_tower') and self.policy.get_vision_tower() is not None:
            interpolate_pos_encoding(self.policy.get_vision_tower(), image_size=320, patch_size=14)
        # 5. âœ…âœ…âœ… å…³é”®ä¿®å¤ï¼šåŠ è½½ non_lora_trainables.binï¼Œæ­£ç¡®å¤„ç† key + è·³è¿‡ä½ç½®ç¼–ç  + æ¸…ç† NaN
        non_lora_path = os.path.join(model_path, 'non_lora_trainables.bin')
        if os.path.exists(non_lora_path):
            print("æ­£åœ¨åŠ è½½ non_lora_trainables.bin...")
            non_lora_weights = torch.load(non_lora_path, map_location='cpu')
            cleaned_weights = {}
            for k, v in non_lora_weights.items():
                # ğŸ”¥ ç§»é™¤ 'base_model.model.' å‰ç¼€ï¼ˆæ ¹æ®ä½ æ—¥å¿—ä¸­çš„ keyï¼‰
                if k.startswith('base_model.model.'):
                    k = k[len('base_model.model.'):]
                # ğŸ”¥ è·³è¿‡ä½ç½®ç¼–ç ï¼ˆé¿å…ä¸æ’å€¼åå†²çªï¼‰
                if 'vision_model.embeddings.position_embedding.weight' in k:
                    print(f"è·³è¿‡ä½ç½®ç¼–ç æƒé‡: {k}")
                    continue
                # ğŸ”¥ æ¸…ç† NaN / Inf
                if torch.isnan(v).any() or torch.isinf(v).any():
                    print(f"âš ï¸ æƒé‡ {k} åŒ…å« NaN/Infï¼Œæ¸…ç†ä¸­...")
                    v = torch.nan_to_num(v, nan=0.0, posinf=1e4, neginf=-1e4)
                # ğŸ”¥ å¼ºåˆ¶ float32
                if v.dtype == torch.float16:
                    v = v.float()
                cleaned_weights[k] = v
            missing, unexpected = self.policy.load_state_dict(cleaned_weights, strict=False)
            print(f"non_lora_trainables åŠ è½½å®Œæˆï¼missing={len(missing)}, unexpected={len(unexpected)}")
        else:
            print("è­¦å‘Š: æœªæ‰¾åˆ° non_lora_trainables.bin")
        # 6. ä¿®å¤ config.concat
        trained_config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)
        self.policy.config = trained_config
        self.config = trained_config
        if not hasattr(self.config, 'concat') or self.config.concat is None:
            self.config.concat = "token_cat"
            self.policy.config.concat = "token_cat"
        self.policy.visual_concat = getattr(self.policy.config, 'concat', 'token_cat')
        print(f"ä¿®å¤å: æ¨¡å‹visual_concatå±æ€§ = {self.policy.visual_concat}")
        # 7. å¼ºåˆ¶ float32 + æ£€æŸ¥ NaN
        self.policy = self.policy.to(torch.float32)
        has_nan = False
        for name, param in self.policy.named_parameters():
            if torch.isnan(param).any():
                print(f"âŒ ä¿®å¤åä»å­˜åœ¨ NaN: {name}")
                has_nan = True
        if not has_nan:
            print("âœ… æ¨¡å‹å‚æ•°ä¸­æœªæ£€æµ‹åˆ° NaN")
        # 8. æ‰“å°æ¨¡å‹è®¾å¤‡
        print(f"æ¨¡å‹å·²åŠ è½½åˆ°è®¾å¤‡: {next(self.policy.parameters()).device}")
        # 9. åˆå§‹åŒ– image_processor
        from transformers import CLIPImageProcessor
        self.image_processor = CLIPImageProcessor.from_pretrained(
            model_base,
            size={"height": 320, "width": 320},
            do_center_crop=False,
            do_normalize=True,
            image_mean=[0.48145466, 0.4578275, 0.40821073],
            image_std=[0.26862954, 0.26130258, 0.27577711],
        )
        self.context_len = 2048
        print("ç­–ç•¥æ¨¡å‹åŠ è½½å®Œæˆï¼ˆå« NaN ä¿®å¤ + ä½ç½®ç¼–ç é€‚é…ï¼‰")
    def _fix_vision_tower_config(self):
        """ä¿®å¤è§†è§‰å¡”é…ç½®ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å›¾åƒå°ºå¯¸"""
        if hasattr(self.policy, 'get_vision_tower') and self.policy.get_vision_tower() is not None:
            vision_tower = self.policy.get_vision_tower()
            if hasattr(vision_tower, 'vision_tower'):
                vision_model = vision_tower.vision_tower
                # è®¾ç½®å›¾åƒå°ºå¯¸ä¸º320
                if hasattr(vision_model, 'config'):
                    vision_model.config.image_size = 320
                if hasattr(vision_model, 'vision_model') and hasattr(vision_model.vision_model, 'config'):
                    vision_model.vision_model.config.image_size = 320
                print("è§†è§‰å¡”é…ç½®å·²ä¿®å¤ä¸º320x320")
    def _unify_dtypes(self):
        """ç»Ÿä¸€æ¨¡å‹çš„æ•°æ®ç±»å‹"""
        # æ£€æŸ¥æ¨¡å‹å½“å‰çš„æ•°æ®ç±»å‹
        current_dtype = next(self.policy.parameters()).dtype
        print(f"æ¨¡å‹å½“å‰æ•°æ®ç±»å‹: {current_dtype}")
        # åœ¨CPUç¯å¢ƒä¸‹å¼ºåˆ¶ä½¿ç”¨float32ä»¥é¿å…halfç²¾åº¦é—®é¢˜
        if not torch.cuda.is_available() and current_dtype == torch.float16:
            print("æ£€æµ‹åˆ°CPUç¯å¢ƒï¼Œå¼ºåˆ¶å°†æ¨¡å‹è½¬æ¢ä¸ºfloat32ä»¥é¿å…halfç²¾åº¦é—®é¢˜")
            self.policy = self.policy.to(torch.float32)
            current_dtype = torch.float32
        # ç¡®ä¿æ‰€æœ‰ç»„ä»¶ä½¿ç”¨ç›¸åŒçš„æ•°æ®ç±»å‹
        if hasattr(self.policy, 'get_vision_tower') and self.policy.get_vision_tower() is not None:
            vision_tower = self.policy.get_vision_tower()
            vision_tower.to(dtype=current_dtype)
        # ç¡®ä¿åŠ¨ä½œå¤´ä½¿ç”¨ç›¸åŒçš„æ•°æ®ç±»å‹
        if hasattr(self.policy, 'action_head'):
            self.policy.action_head.to(dtype=current_dtype)
        print(f"æ¨¡å‹æ•°æ®ç±»å‹å·²ç»Ÿä¸€ä¸º: {current_dtype}")
    def manual_load_components(self, model_path, model_base):
        from transformers import AutoTokenizer, AutoModelForCausalLM
        from llava_pythia.model import LlavaPythiaForCausalLM
        from llava_pythia import LlavaPythiaConfig
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_base or model_path, use_fast=False)
        except:
            from transformers import GPT2Tokenizer
            self.tokenizer = GPT2Tokenizer.from_pretrained(model_base or model_path)
        self.config = LlavaPythiaConfig.from_pretrained(model_path)
        # å…³é”®ä¿®å¤ï¼šåœ¨åŠ è½½æ¨¡å‹å‰è®¾ç½®æ­£ç¡®çš„å›¾åƒå°ºå¯¸
        if hasattr(self.config, 'vision_tower'):
            self.config.vision_tower.image_size = 320
        # ä½¿ç”¨float32é¿å…æ•°æ®ç±»å‹ä¸åŒ¹é…
        self.policy = LlavaPythiaForCausalLM.from_pretrained(
            model_path,
            config=self.config,
            torch_dtype=torch.float32,  # ä½¿ç”¨float32ç¡®ä¿ä¸€è‡´æ€§
            low_cpu_mem_usage=True
        ).cuda()
        # å¼ºåˆ¶è®¾ç½®è§†è§‰ç¼–ç å™¨çš„å›¾åƒå°ºå¯¸
        self._fix_vision_tower_config()
        # ç»Ÿä¸€æ•°æ®ç±»å‹
        self._unify_dtypes()
        from llava_pythia.mm_utils import get_model_name_from_path
        model_name = get_model_name_from_path(model_path)
        if 'llava' in model_name.lower():
            from transformers import CLIPImageProcessor
            # æ˜ç¡®æŒ‡å®š320x320å°ºå¯¸
            self.image_processor = CLIPImageProcessor.from_pretrained(
                model_base or model_path,
                do_resize=True,
                size={"height": 320, "width": 320},
                do_center_crop=False,  # ç¦ç”¨ä¸­å¿ƒè£å‰ªï¼Œä½¿ç”¨resize
                do_normalize=True,
                image_mean=[0.48145466, 0.4578275, 0.40821073],
                image_std=[0.26862954, 0.26130258, 0.27577711],
            )
        else:
            from torchvision import transforms
            self.image_processor = transforms.Compose([
                transforms.Resize((320, 320), antialias=True),
                transforms.ToTensor(),
                transforms.Normalize(
                    mean=[0.48145466, 0.4578275, 0.40821073],
                    std=[0.26862954, 0.26130258, 0.27577711]
                )
            ])
        self.context_len = 2048
        # >>>>>>>>>>>>>>>>>>> æ–°å¢ï¼šåŠ è½½ non_lora_trainables.bin <<<<<<<<<<<<<<<<<<<<<
        import os
        non_lora_path = os.path.join(model_path, 'non_lora_trainables.bin')
        if os.path.exists(non_lora_path):
            print("æ­£åœ¨åŠ è½½ non_lora_trainables.bin (manual mode)...")
            non_lora_weights = torch.load(non_lora_path, map_location='cpu')
            new_weights = {}
            for k, v in non_lora_weights.items():
                if k.startswith('model.'):
                    new_weights[k] = v
                else:
                    new_weights['model.' + k] = v
            missing, unexpected = self.policy.load_state_dict(new_weights, strict=False)
            print(f"non_lora_trainables åŠ è½½å®Œæˆï¼ˆæ‰‹åŠ¨æ¨¡å¼ï¼‰ï¼")
            if missing:
                print(f"Missing keys: {missing}")
            if unexpected:
                print(f"Unexpected keys: {unexpected}")
        else:
            print("è­¦å‘Š: æœªæ‰¾åˆ° non_lora_trainables.binï¼Œè·¯å¾„:", non_lora_path)
        # >>>>>>>>>>>>>>>>>>> æ–°å¢ç»“æŸ <<<<<<<<<<<<<<<<<<<<<
    def process_batch_to_llava(self, curr_image, robo_state, raw_lang):
        """
        é€‚é… image_size=320 çš„æ¨¡å‹ã€‚
        curr_image: (2, H, W, 3) in [0, 1]
        """
        self.conv = conv_templates[self.policy_config['conv_mode']].copy()
        if len(curr_image.shape) == 5:
            curr_image = curr_image.squeeze(0)  # (2, H, W, 3)
        assert curr_image.dim() == 4 and curr_image.shape[0] == 2, f"curr_image shape: {curr_image.shape}"
        # è½¬ä¸º (2, 3, H, W)
        curr_image = curr_image.permute(0, 3, 1, 2)
        
        # >>>>>>>>>> æ–°å¢ï¼šä¿å­˜è¾“å…¥å›¾åƒåˆ° /home/tianxiaoyan/Pictures <<<<<<<<<<
        import os
        import cv2
        output_dir = "/home/tianxiaoyan/Pictures/camera_inputs"
        os.makedirs(output_dir, exist_ok=True)
        
        for i in range(curr_image.shape[0]):
            # å°†å›¾åƒä» [0,1] èŒƒå›´è½¬æ¢åˆ° [0,255] ä¸”è½¬æ¢ä¸º uint8
            img_save = (curr_image[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
            # è½¬æ¢ä¸ºBGRæ ¼å¼ä¿å­˜ï¼ˆOpenCVéœ€è¦ï¼‰
            if img_save.shape[2] == 3:  # RGB image
                img_save = cv2.cvtColor(img_save, cv2.COLOR_RGB2BGR)
            output_path = os.path.join(output_dir, f"camera_input_{i}.jpg")
            cv2.imwrite(output_path, img_save)
        print(f"å·²ä¿å­˜è¾“å…¥å›¾åƒåˆ° {output_dir}")
        # >>>>>>>>>> ç»“æŸæ–°å¢ <<<<<<<<<<
        
        # è·å–æ¨¡å‹çš„æ•°æ®ç±»å‹
        model_dtype = next(self.policy.parameters()).dtype
        # ç»Ÿä¸€çš„å›¾åƒé¢„å¤„ç† - ç¡®ä¿è¾“å‡ºä¸º320x320
        processed_images = []
        for i in range(curr_image.shape[0]):
            img = curr_image[i]  # (3, H, W)
            # === ä¼˜åŒ–ï¼šçº¯ GPU é¢„å¤„ç†ï¼Œé¿å… CPU-GPU æ‹·è´ ===
            # 1. è°ƒæ•´å°ºå¯¸åˆ° 320x320
            img_resized = torch.nn.functional.interpolate(
                img.unsqueeze(0), size=(320, 320), mode='bilinear', align_corners=False
            ).squeeze(0)  # (3, 320, 320)
            # 2. å½’ä¸€åŒ–ï¼ˆä½¿ç”¨ä¸ CLIP ç›¸åŒçš„ mean/stdï¼‰
            mean = torch.tensor([0.48145466, 0.4578275, 0.40821073], device=img.device).view(3, 1, 1)
            std = torch.tensor([0.26862954, 0.26130258, 0.27577711], device=img.device).view(3, 1, 1)
            img_norm = (img_resized - mean) / std
            processed_images.append(img_norm.unsqueeze(0).to(dtype=model_dtype))
        # åˆå¹¶
        image_tensor = torch.cat(processed_images, dim=0).to(self.policy.device)
        # === ä¼˜åŒ–ç»“æŸ ===
        image_tensor_main = image_tensor[0:1]  # ä¸»è§†è§’
        image_tensor_secondary = image_tensor[1:2]  # å‰¯è§†è§’
        inp = raw_lang
        if self.policy.config.mm_use_im_start_end:
            inp = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + '\n' + inp
        else:
            inp = DEFAULT_IMAGE_TOKEN + '\n' + inp
        self.conv.append_message(self.conv.roles[0], inp)
        self.conv.append_message(self.conv.roles[1], None)
        prompt = self.conv.get_prompt() + "  "
        # ç¡®ä¿input_idsä½¿ç”¨æ­£ç¡®è®¾å¤‡
        input_ids = tokenizer_image_token(prompt, self.tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()
        attn_mask = input_ids.ne(self.tokenizer.pad_token_id)
        # ç¡®ä¿çŠ¶æ€ä½¿ç”¨ç›¸åŒçš„æ•°æ®ç±»å‹å’Œè®¾å¤‡
        states = robo_state.to(self.policy.device, dtype=model_dtype)
        return dict(
            input_ids=input_ids,
            attention_mask=attn_mask,
            images=image_tensor_main,
            images_r=image_tensor_secondary,
            states=states
        )
class FrankaROSEnvironment:
    def __init__(self, left_cam_id=4, right_cam_id=10):
        self.left_cam_id = left_cam_id
        self.right_cam_id = right_cam_id
        self.left_cap = None
        self.right_cap = None
        self.joint_positions = np.zeros(7)  # å­˜å‚¨å½“å‰å…³èŠ‚ä½ç½®
        self.current_ee_pose = None  # å­˜å‚¨å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿
        self.init_cameras()
        if not rospy.get_node_uri():
            rospy.init_node('tinyvla_franka_control', anonymous=True)
        self.pose_pub = rospy.Publisher(
            '/cartesian_impedance_example_controller/equilibrium_pose',
            PoseStamped,
            queue_size=1
        )
        # æ·»åŠ å¤¹çˆªæ§åˆ¶å‘å¸ƒè€…
        self.gripper_pub = rospy.Publisher(
            '/franka_gripper/goal_width',
            Float64,
            queue_size=1
        )
        # è®¢é˜…å…³èŠ‚çŠ¶æ€
        self.joint_sub = rospy.Subscriber(
            '/franka_state_controller/joint_states',
            JointState,
            self.joint_state_callback,
            queue_size=1
        )
        # è®¢é˜…æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿
        self.ee_pose_sub = rospy.Subscriber(
            '/cartesian_impedance_example_controller/equilibrium_pose',
            PoseStamped,
            self.ee_pose_callback,
            queue_size=1
        )
        rospy.sleep(1.0)
        print("Franka ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼ˆç¬›å¡å°”æ§åˆ¶æ¨¡å¼ï¼‰")

    def check_joint_safety(self, target_joints):
        """æ£€æŸ¥ç›®æ ‡å…³èŠ‚è§’åº¦æ˜¯å¦åœ¨å®‰å…¨èŒƒå›´å†…"""
        for i in range(min(len(target_joints), 7)):
            if target_joints[i] < FRANKA_JOINT_LIMITS['min'][i] or target_joints[i] > FRANKA_JOINT_LIMITS['max'][i]:
                print(f"è­¦å‘Š: å…³èŠ‚ {i+1} è¶…å‡ºå®‰å…¨èŒƒå›´! å½“å‰å€¼: {target_joints[i]:.3f}, å®‰å…¨èŒƒå›´: [{FRANKA_JOINT_LIMITS['min'][i]:.3f}, {FRANKA_JOINT_LIMITS['max'][i]:.3f}]")
                return False
        return True

    def emergency_stop(self):
        """ç´§æ€¥åœæ­¢æœºæ¢°è‡‚"""
        print("æ‰§è¡Œç´§æ€¥åœæ­¢!")
        # å‘é€å½“å‰ä½ç½®ä½œä¸ºç›®æ ‡ï¼Œä½¿æœºæ¢°è‡‚åœæ­¢ç§»åŠ¨
        msg = PoseStamped()
        msg.header.stamp = rospy.Time.now()
        msg.header.frame_id = "panda_link0"
        msg.pose.position.x = self.joint_positions[0] if len(self.joint_positions) > 0 else 0.0
        msg.pose.position.y = self.joint_positions[1] if len(self.joint_positions) > 1 else 0.0
        msg.pose.position.z = self.joint_positions[2] if len(self.joint_positions) > 2 else 0.3
        msg.pose.orientation.x = 0.0
        msg.pose.orientation.y = 0.0
        msg.pose.orientation.z = 0.0
        msg.pose.orientation.w = 1.0
        self.pose_pub.publish(msg)

        # å‘é€å¤¹çˆªåœæ­¢å‘½ä»¤
        gripper_msg = Float64()
        gripper_msg.data = 0.08  # è®¾ç½®ä¸ºæœ€å¤§å¼€åˆ
        self.gripper_pub.publish(gripper_msg)

        print("ç´§æ€¥åœæ­¢å‘½ä»¤å·²å‘é€")

    def joint_state_callback(self, msg):
        """å…³èŠ‚çŠ¶æ€å›è°ƒå‡½æ•°"""
        # æå–å‰7ä¸ªå…³èŠ‚çš„è§’åº¦
        if len(msg.position) >= 7:
            self.joint_positions = np.array(msg.position[:7])

    def ee_pose_callback(self, msg):
        """æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿å›è°ƒå‡½æ•°"""
        # å­˜å‚¨å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿
        self.current_ee_pose = msg

    def get_current_ee_position(self):
        """è·å–å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®"""
        if self.current_ee_pose is None:
            # å¦‚æœè¿˜æ²¡æœ‰æ¥æ”¶åˆ°ä½å§¿ï¼Œè¿”å›é»˜è®¤å®‰å…¨ä½ç½®
            print("è­¦å‘Š: è¿˜æœªæ¥æ”¶åˆ°æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®")
            return np.array([0.3, 0.0, 0.3])

        return np.array([
            self.current_ee_pose.pose.position.x,
            self.current_ee_pose.pose.position.y,
            self.current_ee_pose.pose.position.z
        ])

    def reset(self, randomize=False):
        print("ç¯å¢ƒé‡ç½®")
        # åœ¨é‡ç½®æ—¶å‘é€ä¸€ä¸ªå®‰å…¨çš„åˆå§‹ä½ç½®
        self.send_safe_position()
        return self.get_observation()

    def send_safe_position(self):
        """å‘é€ä¸€ä¸ªå®‰å…¨çš„åˆå§‹ä½ç½®ï¼Œç¡®ä¿å¤¹çˆªå‘ä¸‹æŒ‡å‘ä¸”æœå‘æ­£ç¡®"""
        print("å‘é€å®‰å…¨åˆå§‹ä½ç½®...")
        # å®‰å…¨ä½ç½®ï¼šX=0.3, Y=0.0, Z=0.3ï¼ˆåœ¨åŸºåº§å‰æ–¹ï¼Œé€‚å½“é«˜åº¦ï¼‰
        # ä½¿ç”¨ä¿®æ­£åçš„å››å…ƒæ•° [0.0, 1.0, 0.0, 0.0] (ç»•Yè½´180åº¦)
        # è¿™ä¸ªå§¿æ€ç¡®ä¿:
        # - Zè½´å‘ä¸‹æŒ‡å‘ [0, 0, -1]
        # - Xè½´å‘åæŒ‡å‘ [-1, 0, 0] (ä¸åŠ¨ä½œä¿®æ­£é€»è¾‘ä¸€è‡´ï¼Œé¿å…æ°´å¹³180åº¦æ—‹è½¬)
        # - Yè½´å‘å³æŒ‡å‘ [0, 1, 0]
        # åœ¨ROSä¸­ï¼Œå››å…ƒæ•°é¡ºåºæ˜¯ [x, y, z, w]
        safe_position = [0.3, 0.0, 0.3, 0.0, 1.0, 0.0, 0.0]  # x, y, z, qx, qy, qz, qw

        msg = PoseStamped()
        msg.header.stamp = rospy.Time.now()
        msg.header.frame_id = "panda_link0"
        msg.pose.position.x = safe_position[0]
        msg.pose.position.y = safe_position[1]
        msg.pose.position.z = safe_position[2]
        msg.pose.orientation.x = safe_position[3]
        msg.pose.orientation.y = safe_position[4]
        msg.pose.orientation.z = safe_position[5]
        msg.pose.orientation.w = safe_position[6]

        print(f"å‘é€å®‰å…¨ä½ç½®: x={safe_position[0]}, y={safe_position[1]}, z={safe_position[2]}")
        print("ç¡®ä¿å¤¹çˆªå‘ä¸‹æŒ‡å‘ä¸”æœå‘æ­£ç¡®...")
        self.pose_pub.publish(msg)
        rospy.sleep(2.0)  # ç­‰å¾…ä½ç½®å‘é€å®Œæˆ

        # éªŒè¯å§¿æ€
        print("éªŒè¯å®‰å…¨å§¿æ€:")
        print(f"  ä½ç½®: x={safe_position[0]}, y={safe_position[1]}, z={safe_position[2]}")
        print(f"  å››å…ƒæ•°: [{safe_position[3]}, {safe_position[4]}, {safe_position[5]}, {safe_position[6]}]")
        print("  âœ… å¤¹çˆªåº”è¯¥å‘ä¸‹æŒ‡å‘ä¸”æœå‘æ­£ç¡®")

        # éªŒè¯å››å…ƒæ•°æ˜¯å¦æ­£ç¡®
        from scipy.spatial.transform import Rotation as R
        r = R.from_quat([safe_position[3], safe_position[4], safe_position[5], safe_position[6]])
        z_axis = r.apply([0, 0, 1])
        x_axis = r.apply([1, 0, 0])
        y_axis = r.apply([0, 1, 0])

        print(f"  éªŒè¯Zè½´: [{z_axis[0]:.3f}, {z_axis[1]:.3f}, {z_axis[2]:.3f}] {'âœ…å‘ä¸‹' if z_axis[2] < -0.9 else 'âŒä¸å‘ä¸‹'}")
        print(f"  éªŒè¯Xè½´: [{x_axis[0]:.3f}, {x_axis[1]:.3f}, {x_axis[2]:.3f}] {'âœ…å‘å' if x_axis[0] < -0.9 else 'âŒ'}")
        print(f"  éªŒè¯Yè½´: [{y_axis[0]:.3f}, {y_axis[1]:.3f}, {y_axis[2]:.3f}] {'âœ…å‘å³' if y_axis[1] > 0.9 else 'âŒ'}")

        # æ£€æŸ¥æ˜¯å¦ä¸åŠ¨ä½œä¿®æ­£é€»è¾‘ä¸€è‡´ï¼ˆé¿å…æ°´å¹³æ—‹è½¬180åº¦çš„é—®é¢˜ï¼‰
        if x_axis[0] < -0.9 and y_axis[1] > 0.9:  # Xè½´å‘åï¼ŒYè½´å‘å³
            print("  âœ… å§¿æ€ä¸åŠ¨ä½œä¿®æ­£é€»è¾‘ä¸€è‡´ï¼Œé¿å…äº†æ°´å¹³æ—‹è½¬180åº¦é—®é¢˜")
        else:
            print("  âŒ å§¿æ€ä¸åŠ¨ä½œä¿®æ­£é€»è¾‘ä¸ä¸€è‡´ï¼Œå¯èƒ½å¯¼è‡´æ—‹è½¬é—®é¢˜")
    def init_cameras(self):
        print("åˆå§‹åŒ–RealSenseæ‘„åƒå¤´...")
        self.left_cap = cv2.VideoCapture(self.left_cam_id)
        self.right_cap = cv2.VideoCapture(self.right_cam_id)
        for cap, name in [(self.left_cap, "å·¦"), (self.right_cap, "å³")]:
            if not cap.isOpened():
                print(f"é”™è¯¯: æ— æ³•æ‰“å¼€{name}æ‘„åƒå¤´")
            else:
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                cap.set(cv2.CAP_PROP_FPS, 30)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        print("æ‘„åƒå¤´åˆå§‹åŒ–å®Œæˆ")
    def get_images(self):
        left_image = np.ones((480, 640, 3), dtype=np.uint8) * 128
        right_image = np.ones((480, 640, 3), dtype=np.uint8) * 128
        if self.left_cap and self.left_cap.isOpened():
            ret, img = self.left_cap.read()
            if ret: left_image = img
        if self.right_cap and self.right_cap.isOpened():
            ret, img = self.right_cap.read()
            if ret: right_image = img
        return left_image, right_image
    def get_observation(self):
        left_img, right_img = self.get_images()
        if left_img.shape != right_img.shape:
            min_h = min(left_img.shape[0], right_img.shape[0])
            min_w = min(left_img.shape[1], right_img.shape[1])
            left_img = cv2.resize(left_img, (min_w, min_h))
            right_img = cv2.resize(right_img, (min_w, min_h))
        images = np.stack([left_img, right_img], axis=0)
        state = np.zeros(7)
        return images, state
    def step(self, action):
        print(f"æ¥æ”¶åˆ°åŠ¨ä½œ: {action}")
        print(f"åŠ¨ä½œç»´åº¦: {len(action)}")
        print(f"å‘å¸ƒä½å§¿: pos=({action[0]:.3f}, {action[1]:.3f}, {action[2]:.3f})")

        # æ£€æŸ¥æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®æ˜¯å¦åœ¨å®‰å…¨èŒƒå›´å†…
        safety_check_passed = True
        safety_violations = []

        # æ›´ä¸¥æ ¼çš„Xè½´æ£€æŸ¥ï¼ˆé˜²æ­¢æœå‘åŸºåº§ï¼‰
        # Xè½´æ­£å€¼è¡¨ç¤ºå‘å‰ï¼Œè´Ÿå€¼è¡¨ç¤ºå‘åï¼ˆæœå‘åŸºåº§ï¼‰
        if action[0] < 0.1 or action[0] > 0.6:
            safety_violations.append(f"Xè½´è¶…å‡ºå®‰å…¨èŒƒå›´: {action[0]:.3f} (å»ºè®®èŒƒå›´: 0.1-0.6)")
            safety_check_passed = False

        # Yè½´æ£€æŸ¥ï¼ˆå·¦å³ç§»åŠ¨ï¼‰
        if action[1] < -0.4 or action[1] > 0.4:
            safety_violations.append(f"Yè½´è¶…å‡ºå®‰å…¨èŒƒå›´: {action[1]:.3f}")
            safety_check_passed = False

        # Zè½´æ£€æŸ¥ï¼ˆä¸Šä¸‹ç§»åŠ¨ï¼‰
        if action[2] < 0.05 or action[2] > 0.7:
            safety_violations.append(f"Zè½´è¶…å‡ºå®‰å…¨èŒƒå›´: {action[2]:.3f} (å»ºè®®èŒƒå›´: 0.05-0.7)")
            safety_check_passed = False

        # ç‰¹æ®Šæ£€æŸ¥ï¼šé˜²æ­¢è¿‡äºé è¿‘åŸºåº§
        distance_from_base = np.sqrt(action[0]**2 + action[1]**2)
        if distance_from_base < 0.15:
            safety_violations.append(f"è·ç¦»åŸºåº§è¿‡è¿‘: {distance_from_base:.3f}m")
            safety_check_passed = False

        if not safety_check_passed:
            print("å®‰å…¨æ£€æŸ¥å¤±è´¥:")
            for violation in safety_violations:
                print(f"  - {violation}")
            print("ä½¿ç”¨å®‰å…¨ä½ç½®æ›¿ä»£å±é™©åŠ¨ä½œ")

            # ä½¿ç”¨å®‰å…¨ä½ç½®è€Œä¸æ˜¯ç®€å•è£å‰ª
            safe_action = action.copy()
            # ç¡®ä¿Xè½´åœ¨å®‰å…¨èŒƒå›´å†…ï¼ˆé˜²æ­¢æœå‘åŸºåº§ï¼‰
            safe_action[0] = max(0.15, min(0.5, action[0]))
            # ç¡®ä¿Yè½´åœ¨å®‰å…¨èŒƒå›´å†…
            safe_action[1] = max(-0.3, min(0.3, action[1]))
            # ç¡®ä¿Zè½´åœ¨å®‰å…¨èŒƒå›´å†…
            safe_action[2] = max(0.1, min(0.6, action[2]))

            # ç¡®ä¿ä¸ä¼šè¿‡äºé è¿‘åŸºåº§ä¸­å¿ƒ
            distance = np.sqrt(safe_action[0]**2 + safe_action[1]**2)
            if distance < 0.15:
                # è°ƒæ•´Xå€¼ä»¥ç¡®ä¿è¶³å¤Ÿçš„è·ç¦»
                safe_action[0] = 0.15 if safe_action[0] >= 0 else -0.15

            action = safe_action
            print(f"ä¿®æ­£åçš„ä½ç½®: pos=({action[0]:.3f}, {action[1]:.3f}, {action[2]:.3f})")

        # é¢å¤–çš„å§¿æ€å®‰å…¨æ€§æ£€æŸ¥
        if len(action) >= 7:
            # æ£€æŸ¥å››å…ƒæ•°æ˜¯å¦æœ‰æ•ˆ
            quat = action[3:7]
            quat_norm = np.linalg.norm(quat)

            if abs(quat_norm - 1.0) > 0.1:  # å¦‚æœå››å…ƒæ•°èŒƒæ•°åç¦»å•ä½å››å…ƒæ•°å¤ªå¤š
                print(f"è­¦å‘Š: å››å…ƒæ•°èŒƒæ•°å¼‚å¸¸ ({quat_norm:.3f})ï¼Œä½¿ç”¨é»˜è®¤å§¿æ€")
                # ä½¿ç”¨ç¡®å®šçš„å‘ä¸‹æŒ‡å‘å§¿æ€ [0, 1, 0, 0] (ç»•Yè½´180åº¦)
                # è¿™ä¸ªå§¿æ€ç¡®ä¿æœ«ç«¯æ‰§è¡Œå™¨Zè½´å‘ä¸‹æŒ‡å‘[0, 0, -1]ï¼Œé¿å…å³åæ–¹æ—‹è½¬é—®é¢˜
                print("âŒ å››å…ƒæ•°å¼‚å¸¸ï¼Œä½¿ç”¨ç¡®å®šçš„å®‰å…¨å‘ä¸‹æŒ‡å‘å§¿æ€ [0, 1, 0, 0]")
                action[3:7] = np.array([0.0, 1.0, 0.0, 0.0])  # å‘ä¸‹æŒ‡å‘çš„å››å…ƒæ•°

                # éªŒè¯å®‰å…¨å§¿æ€
                r_safe = R.from_quat(action[3:7])
                safe_z_direction = r_safe.apply([0, 0, 1])
                safe_x_direction = r_safe.apply([1, 0, 0])
                safe_y_direction = r_safe.apply([0, 1, 0])

                print(f"âœ… å®‰å…¨å§¿æ€éªŒè¯:")
                print(f"   å››å…ƒæ•°: {action[3:7]}")
                print(f"   Zè½´: [{safe_z_direction[0]:.3f}, {safe_z_direction[1]:.3f}, {safe_z_direction[2]:.3f}] (åº”ä¸º[0,0,-1])")
                print(f"   Xè½´: [{safe_x_direction[0]:.3f}, {safe_x_direction[1]:.3f}, {safe_x_direction[2]:.3f}] (åº”ä¸º[-1,0,0])")
                print(f"   Yè½´: [{safe_y_direction[0]:.3f}, {safe_y_direction[1]:.3f}, {safe_y_direction[2]:.3f}] (åº”ä¸º[0,1,0])")

            # æ£€æŸ¥å§¿æ€æ˜¯å¦åˆç†ï¼ˆé¿å…æç«¯å§¿æ€ï¼‰
            try:
                from scipy.spatial.transform import Rotation as R
                r = R.from_quat(quat)
                euler = r.as_euler('xyz', degrees=True)

                print(f"å½“å‰å§¿æ€æ¬§æ‹‰è§’: roll={euler[0]:.2f}Â°, pitch={euler[1]:.2f}Â°, yaw={euler[2]:.2f}Â°")

                # æ£€æŸ¥Zè½´æ–¹å‘æ˜¯å¦å‘ä¸‹ï¼ˆé€‚åˆæŠ“å–ï¼‰
                z_direction = r.apply([0, 0, 1])  # åº”ç”¨æ—‹è½¬åˆ°åŸå§‹Zè½´
                print(f"å½“å‰Zè½´æ–¹å‘: [{z_direction[0]:.3f}, {z_direction[1]:.3f}, {z_direction[2]:.3f}]")

                # å¦‚æœZè½´ä¸æ˜¯å‘ä¸‹æŒ‡å‘ï¼ˆZåˆ†é‡åº”è¯¥æ¥è¿‘-1ï¼‰
                if z_direction[2] > -0.5:  # å¦‚æœä¸æ˜¯æ˜æ˜¾å‘ä¸‹æŒ‡å‘
                    print(f"è­¦å‘Š: Zè½´æ–¹å‘å¼‚å¸¸ ({z_direction[2]:.3f})ï¼Œè°ƒæ•´ä¸ºå‘ä¸‹æŒ‡å‘å§¿æ€")
                    # ä½¿ç”¨ç¡®å®šçš„å‘ä¸‹æŒ‡å‘å§¿æ€ [0, 1, 0, 0] (ç»•Yè½´180åº¦)
                    # è¿™ä¸ªå§¿æ€ç¡®ä¿æœ«ç«¯æ‰§è¡Œå™¨Zè½´å‘ä¸‹æŒ‡å‘[0, 0, -1]ï¼Œé¿å…å³åæ–¹æ—‹è½¬é—®é¢˜
                    print("âš ï¸ å®‰å…¨æ£€æŸ¥: æ£€æµ‹åˆ°å§¿æ€å¼‚å¸¸ï¼Œå¼ºåˆ¶è®¾ç½®ä¸ºæ ‡å‡†å‘ä¸‹æŒ‡å‘å§¿æ€")
                    action[3:7] = np.array([0.0, 1.0, 0.0, 0.0])

                    # éªŒè¯ä¿®æ­£æ•ˆæœ
                    r_fixed = R.from_quat(action[3:7])
                    fixed_z_direction = r_fixed.apply([0, 0, 1])
                    fixed_x_direction = r_fixed.apply([1, 0, 0])
                    fixed_y_direction = r_fixed.apply([0, 1, 0])

                    print(f"âœ… å®‰å…¨ä¿®æ­£å®Œæˆ:")
                    print(f"   ä¿®æ­£åå››å…ƒæ•°: {action[3:7]}")
                    print(f"   Zè½´æ–¹å‘: [{fixed_z_direction[0]:.3f}, {fixed_z_direction[1]:.3f}, {fixed_z_direction[2]:.3f}] (åº”ä¸º[0,0,-1])")
                    print(f"   Xè½´æ–¹å‘: [{fixed_x_direction[0]:.3f}, {fixed_x_direction[1]:.3f}, {fixed_x_direction[2]:.3f}] (åº”ä¸º[-1,0,0])")
                    print(f"   Yè½´æ–¹å‘: [{fixed_y_direction[0]:.3f}, {fixed_y_direction[1]:.3f}, {fixed_y_direction[2]:.3f}] (åº”ä¸º[0,1,0])")

            except Exception as e:
                print(f"å§¿æ€æ£€æŸ¥é”™è¯¯: {e}")
                # å‡ºé”™æ—¶ä½¿ç”¨å®‰å…¨å§¿æ€
                action[3:7] = np.array([0.0, 1.0, 0.0, 0.0])

        # å‘å¸ƒç¬›å¡å°”ä½å§¿
        msg = PoseStamped()
        msg.header.stamp = rospy.Time.now()
        msg.header.frame_id = "panda_link0"
        msg.pose.position.x = action[0]
        msg.pose.position.y = action[1]
        msg.pose.position.z = action[2]
        msg.pose.orientation.x = action[3]
        msg.pose.orientation.y = action[4]
        msg.pose.orientation.z = action[5]
        msg.pose.orientation.w = action[6]
        print("å‘å¸ƒçš„ä½å§¿æ¶ˆæ¯:")
        print(msg)
        self.pose_pub.publish(msg)

        # å‘å¸ƒå¤¹çˆªæ§åˆ¶å‘½ä»¤ï¼ˆå¦‚æœåŠ¨ä½œåŒ…å«å¤¹çˆªæ§åˆ¶ï¼‰
        # æ³¨æ„: åŠ¨ä½œæ ¼å¼ä¸º [x, y, z, rot_6d(6ç»´), gripper(1ç»´)] = 10ç»´
        # å¤¹çˆªåœ¨ç´¢å¼•9 (ç¬¬10ç»´)
        if len(action) >= 10:
            # å¤¹çˆªæ§åˆ¶å€¼å·²ç»åœ¨convert_actionså‡½æ•°ä¸­è½¬æ¢ä¸ºç‰©ç†å•ä½ï¼ˆç±³ï¼‰
            gripper_width = action[9]  # ç¬¬10ä¸ªå…ƒç´ æ˜¯å¤¹çˆªå®½åº¦ï¼ˆç±³ï¼‰
            # é™åˆ¶å¤¹çˆªå®½åº¦åœ¨åˆç†èŒƒå›´å†…
            gripper_width = max(0.0, min(0.08, gripper_width))
            gripper_msg = Float64()
            gripper_msg.data = gripper_width
            print(f"å‘å¸ƒå¤¹çˆªæ§åˆ¶å‘½ä»¤: {gripper_width:.3f}m")
            self.gripper_pub.publish(gripper_msg)
        else:
            print("åŠ¨ä½œä¸åŒ…å«å¤¹çˆªæ§åˆ¶ä¿¡æ¯")

        return self.get_observation(), False, {}
    def __del__(self):
        if self.left_cap: self.left_cap.release()
        if self.right_cap: self.right_cap.release()
def debug_model_outputs(policy, batch, step):
    """è°ƒè¯•æ¨¡å‹è¾“å‡º"""
    print(f"\n=== æ­¥éª¤ {step} è°ƒè¯•ä¿¡æ¯ ===")
    # æ£€æŸ¥è¾“å…¥æ•°æ®
    for key, value in batch.items():
        if isinstance(value, torch.Tensor):
            print(f"è¾“å…¥ {key}: shape={value.shape}, range=[{value.min():.3f}, {value.max():.3f}], "
                  f"NaN={torch.isnan(value).any()}, Inf={torch.isinf(value).any()}")
    # æ£€æŸ¥æ¨¡å‹å‚æ•°
    model_params = list(policy.policy.parameters())
    if model_params:
        first_param = model_params[0]
        print(f"æ¨¡å‹å‚æ•°: shape={first_param.shape}, range=[{first_param.min():.3f}, {first_param.max():.3f}], "
              f"NaN={torch.isnan(first_param).any()}, Inf={torch.isinf(first_param).any()}")
    print("=== è°ƒè¯•ç»“æŸ ===\n")


def test_quaternion_continuity():
    """æµ‹è¯•å››å…ƒæ•°è¿ç»­æ€§å¤„ç†å‡½æ•°"""
    print("æµ‹è¯•å››å…ƒæ•°è¿ç»­æ€§å¤„ç†...")

    # æµ‹è¯•ç”¨ä¾‹1: æ­£å¸¸æƒ…å†µ
    q1 = np.array([0.0, 0.0, 0.0, 1.0])  # å•ä½å››å…ƒæ•°
    q2 = np.array([0.1, 0.0, 0.0, 0.995])  # æ¥è¿‘å•ä½å››å…ƒæ•°
    result = ensure_quaternion_continuity(q2, q1)
    print(f"æµ‹è¯•1 - åŸå§‹: {q2}, ç»“æœ: {result}, æ˜¯å¦ç›¸ç­‰: {np.allclose(q2, result)}")

    # æµ‹è¯•ç”¨ä¾‹2: ç¬¦å·ç›¸åçš„æƒ…å†µ
    q1 = np.array([0.0, 0.0, 0.0, 1.0])
    q2 = np.array([0.0, 0.0, 0.0, -1.0])  # ç›¸åç¬¦å·
    result = ensure_quaternion_continuity(q2, q1)
    print(f"æµ‹è¯•2 - åŸå§‹: {q2}, ç»“æœ: {result}, æ˜¯å¦å–å: {np.allclose(result, -q2)}")

    print("å››å…ƒæ•°è¿ç»­æ€§æµ‹è¯•å®Œæˆ")
def eval_bc(policy, deploy_env, policy_config, save_episode=True, num_rollouts=1, raw_lang=None):
    assert raw_lang is not None, "raw lang is None!!!!!!"
    set_seed(0)
    rand_crop_resize = False
    temporal_agg = True
    action_dim = policy.config.action_dim
    policy.policy.eval()
    import pickle
    stats_path = os.path.join(policy_config['model_path'], 'dataset_stats.pkl')
    with open(stats_path, 'rb') as f:
        stats = pickle.load(f)
    post_process = lambda a: a * stats['action_std'] + stats['action_mean']
    env = deploy_env
    query_frequency = policy.config.chunk_size / 2
    if temporal_agg:
        query_frequency = 1
        num_queries = policy.config.chunk_size
    max_timesteps = int(10000)
    # ä¼˜åŒ–ç»ˆæ­¢æ¡ä»¶
    max_duration = 60  # å¢åŠ æœ€å¤§è¿è¡Œæ—¶é—´åˆ°60ç§’
    target_reached_threshold = 0.01  # é™ä½ä½ç½®é˜ˆå€¼ï¼Œæé«˜ç²¾åº¦
    min_steps_for_completion = 100  # è‡³å°‘æ‰§è¡Œ100æ­¥æ‰è€ƒè™‘ç»ˆæ­¢
    for rollout_id in range(num_rollouts):
        env.reset(randomize=False)
        print(f"env has reset!")
        model_dtype = next(policy.policy.parameters()).dtype
        if temporal_agg:
            all_time_actions = torch.zeros([max_timesteps, max_timesteps + num_queries, action_dim], dtype=model_dtype).cuda()
        image_list = []
        robot_state_list = []
        target_action_list = []
        start_time = time.time()
        last_position = None
        last_action = None  # æ·»åŠ ä¸Šä¸€ä¸ªåŠ¨ä½œè®°å½•ï¼Œç”¨äºå¹³æ»‘
        stationary_count = 0
        success_count = 0
        with torch.inference_mode():
            time0 = time.time()
            DT = 1 / FPS
            culmulated_delay = 0
            for t in range(max_timesteps):
                # æ£€æŸ¥è¿è¡Œæ—¶é—´é™åˆ¶
                current_time = time.time()
                if current_time - start_time > max_duration:
                    print(f"è¾¾åˆ°æœ€å¤§è¿è¡Œæ—¶é—´ {max_duration} ç§’ï¼Œåœæ­¢æ‰§è¡Œ")
                    break
                obs = deploy_env.get_observation()
                traj_rgb_np, robot_state = get_obs(obs, stats)
                image_list.append(traj_rgb_np)
                robot_state = torch.from_numpy(robot_state).to(dtype=model_dtype).cuda().unsqueeze(0)
                if t % query_frequency == 0:
                    curr_image = torch.from_numpy(traj_rgb_np / 255.0).to(dtype=model_dtype).cuda()
                if t == 0:
                    for _ in range(10):
                        batch = policy.process_batch_to_llava(curr_image, robot_state, raw_lang)
                        policy.policy(**batch, eval=True)
                    print('network warm up done')
                    time1 = time.time()
                # å®šæœŸé‡ç½®æ¨¡å‹çŠ¶æ€ï¼Œé˜²æ­¢æ•°å€¼ç´¯ç§¯è¯¯å·®
                if t > 0 and t % 50 == 0:
                    print(f"æ­¥éª¤ {t}: é‡ç½®æ¨¡å‹çŠ¶æ€ä»¥ä¿æŒæ•°å€¼ç¨³å®šæ€§")
                    # é‡æ–°è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
                    policy.policy.eval()
                    # æ¸…é™¤å¯èƒ½çš„ç¼“å­˜
                    if hasattr(policy.policy, 'clear_cache'):
                        policy.policy.clear_cache()
                if policy_config['action_head_type'] in ["act", "droid_diffusion"]:
                    if t % query_frequency == 0:
                        batch = policy.process_batch_to_llava(curr_image, robot_state, raw_lang)
                        # æ·»åŠ è¾“å…¥æ•°æ®æ£€æŸ¥
                        for key, value in batch.items():
                            if isinstance(value, torch.Tensor):
                                if torch.any(torch.isnan(value)):
                                    print(f"è­¦å‘Š: è¾“å…¥æ•°æ® {key} åŒ…å«NaNå€¼")
                                    # ä½¿ç”¨å®‰å…¨å€¼æ›¿æ¢
                                    batch[key] = torch.nan_to_num(value, nan=0.0)
                        # åœ¨å…³é”®æ­¥éª¤æ·»åŠ è°ƒè¯•
                        if t % 20 == 0:  # æ¯20æ­¥è°ƒè¯•ä¸€æ¬¡
                            debug_model_outputs(policy, batch, t)
                        all_actions = policy.policy(**batch, eval=True)
                        # æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ˜¯å¦åŒ…å«NaN
                        if torch.any(torch.isnan(all_actions)):
                            print(f"è­¦å‘Š: æ¨¡å‹è¾“å‡ºåŒ…å«NaNå€¼ï¼Œä½¿ç”¨é›¶åŠ¨ä½œ")
                            all_actions = torch.zeros_like(all_actions)
                    if temporal_agg:
                        all_time_actions[[t], t:t + num_queries] = all_actions
                        actions_for_curr_step = all_time_actions[:, t]
                        actions_populated = torch.all(actions_for_curr_step != 0, axis=1)
                        actions_for_curr_step = actions_for_curr_step[actions_populated]
                        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„åŠ¨ä½œ
                        if len(actions_for_curr_step) == 0:
                            print(f"è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„åŠ¨ä½œï¼Œä½¿ç”¨é›¶åŠ¨ä½œ")
                            raw_action = torch.zeros((1, action_dim), dtype=model_dtype).cuda()
                        else:
                            k = 0.01
                            exp_weights = np.exp(-k * np.arange(len(actions_for_curr_step)))
                            exp_weights = exp_weights / exp_weights.sum()
                            exp_weights = torch.from_numpy(exp_weights).cuda().to(dtype=actions_for_curr_step.dtype).unsqueeze(dim=1)
                            raw_action = (actions_for_curr_step * exp_weights).sum(dim=0, keepdim=True)
                    else:
                        raw_action = all_actions[:, t % int(query_frequency)]
                else:
                    raise NotImplementedError
                print(f"raw action size: {raw_action.size()}")
                # æ£€æŸ¥åŸå§‹åŠ¨ä½œæ˜¯å¦åŒ…å«NaN
                if torch.any(torch.isnan(raw_action)):
                    print(f"è­¦å‘Š: åŸå§‹åŠ¨ä½œåŒ…å«NaNå€¼ï¼Œä½¿ç”¨é›¶åŠ¨ä½œ")
                    raw_action = torch.zeros_like(raw_action)
                raw_action = raw_action.squeeze(0).cpu().numpy()
                # æ£€æŸ¥numpyæ•°ç»„æ˜¯å¦åŒ…å«NaN
                if np.any(np.isnan(raw_action)):
                    print(f"è­¦å‘Š: è½¬æ¢åçš„åŠ¨ä½œåŒ…å«NaNå€¼ï¼Œä½¿ç”¨é›¶åŠ¨ä½œ")
                    raw_action = np.zeros_like(raw_action)
                # æ·»åŠ è°ƒè¯•è¾“å‡º
                print(f"åŸå§‹æ¨¡å‹è¾“å‡º (raw_action): {raw_action}")
                print(f"åŸå§‹æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {raw_action.shape}")
                action = post_process(raw_action)
                print(f"åå¤„ç†åçš„åŠ¨ä½œ (post_process): {action}")
                print(f"after post_process action size: {action.shape}")
                # æ ¹æ®ä»»åŠ¡ç±»å‹ä¼ é€’å‚æ•°ç»™åŠ¨ä½œè½¬æ¢å‡½æ•°
                task_type = "pick_up_bowl" if "bowl" in raw_lang.lower() else "general"
                # ä½¿ç”¨åŠ¨ä½œå¹³æ»‘ï¼Œæ ¹æ®æ­¥æ•°è°ƒæ•´å¹³æ»‘å› å­
                # æ—©æœŸæ­¥æ•°ä½¿ç”¨è¾ƒå¼ºå¹³æ»‘ï¼ŒåæœŸå‡å°‘å¹³æ»‘
                if t < 50:
                    smoothing_factor = 0.5  # å‰50æ­¥ä½¿ç”¨è¾ƒå¼ºå¹³æ»‘
                elif t < 100:
                    smoothing_factor = 0.3  # 50-100æ­¥ä½¿ç”¨ä¸­ç­‰å¹³æ»‘
                else:
                    smoothing_factor = 0.1  # 100æ­¥åä½¿ç”¨è¾ƒå¼±å¹³æ»‘

                # âœ… è·å–å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®
                current_ee_pos = deploy_env.get_current_ee_position()
                print(f"æ­¥éª¤ {t}: å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®: {current_ee_pos}")

                # åœ¨è½¬æ¢åŠ¨ä½œä¹‹å‰ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨å¼‚å¸¸å¤§çš„è·³è·ƒ
                if last_action is not None:
                    # æ£€æŸ¥ä½ç½®å˜åŒ–æ˜¯å¦è¿‡å¤§
                    pos_change = np.linalg.norm(action[:3] - last_action[:3])
                    if pos_change > 0.2:  # å¦‚æœä½ç½®å˜åŒ–è¶…è¿‡20cmï¼Œå¯èƒ½æ˜¯å¼‚å¸¸å€¼
                        print(f"è­¦å‘Š: æ£€æµ‹åˆ°å¼‚å¸¸å¤§çš„ä½ç½®å˜åŒ– ({pos_change:.3f}m)ï¼Œåº”ç”¨é™åˆ¶")
                        # é™åˆ¶ä½ç½®å˜åŒ–
                        direction = action[:3] - last_action[:3]
                        direction = direction / np.linalg.norm(direction)
                        action[:3] = last_action[:3] + direction * 0.2

                # âœ… ä¼ å…¥å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®ï¼Œå°†actionè§£é‡Šä¸ºç›¸å¯¹ä½ç§»
                action = convert_actions(action, task_type=task_type,
                                        last_action=last_action,
                                        smoothing_factor=smoothing_factor,
                                        current_ee_pos=current_ee_pos)

                # åŠ¨ä½œåå¤„ç†ï¼šæ£€æŸ¥å››å…ƒæ•°æ˜¯å¦æœ‰æ•ˆ
                if len(action) >= 7:
                    quat = action[3:7]
                    quat_norm = np.linalg.norm(quat)
                    if abs(quat_norm - 1.0) > 0.1:
                        print(f"è­¦å‘Š: å››å…ƒæ•°èŒƒæ•°å¼‚å¸¸ ({quat_norm:.3f})ï¼Œé‡æ–°å½’ä¸€åŒ–")
                        if quat_norm > 0:
                            action[3:7] = quat / quat_norm
                        else:
                            action[3:7] = np.array([0.0, 0.0, 0.0, 1.0])  # ä½¿ç”¨å•ä½å››å…ƒæ•°

                # å¤¹çˆªæ§åˆ¶å¹³æ»‘å¤„ç†
                # æ³¨æ„: åŠ¨ä½œæ ¼å¼ä¸º [x, y, z, rot_6d(6ç»´), gripper(1ç»´)] = 10ç»´
                # å¤¹çˆªåœ¨ç´¢å¼•9 (ç¬¬10ç»´)
                if len(action) >= 10 and last_action is not None and len(last_action) >= 10:
                    # å¯¹å¤¹çˆªæ§åˆ¶è¿›è¡Œå¹³æ»‘å¤„ç†ï¼Œé¿å…çªå˜
                    current_gripper = action[9]
                    last_gripper = last_action[9]
                    gripper_change = abs(current_gripper - last_gripper)

                    # å¦‚æœå¤¹çˆªå˜åŒ–è¿‡å¤§ï¼Œè¿›è¡Œé™åˆ¶
                    if gripper_change > 0.02:  # 2cmçš„å˜åŒ–é™åˆ¶
                        print(f"è­¦å‘Š: å¤¹çˆªå˜åŒ–è¿‡å¤§ ({gripper_change:.3f}m)ï¼Œè¿›è¡Œé™åˆ¶")
                        max_change = 0.02
                        if current_gripper > last_gripper:
                            action[9] = last_gripper + max_change
                        else:
                            action[9] = last_gripper - max_change
                        print(f"å¤¹çˆªå€¼ä» {current_gripper:.3f} è°ƒæ•´ä¸º {action[9]:.3f}")
                print(f'step {t}, æœ€ç»ˆåŠ¨ä½œ (pred action): {action}')
                # ä¼˜åŒ–ä½ç½®æ£€æµ‹å’Œç»ˆæ­¢æ¡ä»¶
                current_position = action[:3]
                if last_position is not None:
                    position_change = np.linalg.norm(current_position - last_position)
                    # åªæœ‰å½“æ‰§è¡Œè¶³å¤Ÿæ­¥æ•°åæ‰å¼€å§‹æ£€æµ‹ç¨³å®šæ€§
                    if t > min_steps_for_completion:
                        if position_change < target_reached_threshold:
                            stationary_count += 1
                        else:
                            stationary_count = 0
                            success_count = 0
                        # æ£€æŸ¥æ˜¯å¦æˆåŠŸæ¥è¿‘ç›®æ ‡ï¼ˆåŸºäºåŠ¨ä½œç¨³å®šæ€§è€Œä¸æ˜¯é¢„è®¾ä½ç½®ï¼‰
                        # ç§»é™¤ç¡¬ç¼–ç çš„ç›®æ ‡ä½ç½®æ£€æµ‹ï¼Œè®©æ¨¡å‹è‡ªä¸»å†³å®šä½•æ—¶å®Œæˆä»»åŠ¡
                        # åªåŸºäºåŠ¨ä½œç¨³å®šæ€§æ¥åˆ¤æ–­ä»»åŠ¡å®Œæˆ
                        if position_change < target_reached_threshold:
                            success_count += 1
                        else:
                            success_count = 0
                        # æ”¹è¿›çš„ç»ˆæ­¢æ¡ä»¶
                        # éœ€è¦åŒæ—¶æ»¡è¶³ï¼šä½ç½®ç¨³å®š ä¸” æ‰§è¡Œè¶³å¤Ÿæ­¥æ•°
                        if (stationary_count > 30 and
                            success_count > 20 and
                            t > min_steps_for_completion):
                            print(f"ä»»åŠ¡å®Œæˆï¼æœºå™¨äººä½ç½®å·²ç¨³å®šï¼Œåœæ­¢æ‰§è¡Œ")
                            print(f"æœ€ç»ˆä½ç½®: {current_position}")
                            break
                last_position = current_position.copy()
                last_action = action.copy()  # æ›´æ–°ä¸Šä¸€ä¸ªåŠ¨ä½œ
                obs, done, info = deploy_env.step(action)

                # æ·»åŠ é¢å¤–çš„å®‰å…¨æ£€æŸ¥
                # æ£€æŸ¥å…³èŠ‚ä½ç½®æ˜¯å¦è¶…å‡ºå®‰å…¨èŒƒå›´
                if hasattr(deploy_env, 'joint_positions') and len(deploy_env.joint_positions) >= 7:
                    if not deploy_env.check_joint_safety(deploy_env.joint_positions):
                        print("æ£€æµ‹åˆ°å…³èŠ‚è¶…å‡ºå®‰å…¨èŒƒå›´ï¼Œæ‰§è¡Œç´§æ€¥åœæ­¢!")
                        deploy_env.emergency_stop()
                        break  # åœæ­¢æ‰§è¡Œ

                robot_state_list.append(robot_state)
                target_action_list.append(action)
                duration = time.time() - time1
                sleep_time = max(0, DT - duration)
                time.sleep(sleep_time)
                if duration >= DT:
                    culmulated_delay += (duration - DT)
                    print(f'Warning: step duration: {duration:.3f} s at step {t} longer than DT: {DT} s, culmulated delay: {culmulated_delay:.3f} s')
                # æ·»åŠ é”®ç›˜ä¸­æ–­æ£€æŸ¥
                if rospy.is_shutdown():
                    print("ROSå…³é—­ä¿¡å·æ¥æ”¶ï¼Œåœæ­¢æ‰§è¡Œ")
                    break
            print(f'Avg fps {max_timesteps / (time.time() - time0)}')
            plt.close()
    return
if __name__ == '__main__':
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    action_head = 'droid_diffusion'
    policy_config = {
        "model_path": "/home/tianxiaoyan/TinyVLA/output/droid_multi_task_processed_latest",
        "model_base": "./checkpoints/llava-pythia-13b",
        "enable_lora": True,
        "conv_mode": "pythia",
        "action_head": action_head,
        "action_head_type": action_head,
    }
    raw_lang = 'pick up the white bowl'
    try:
        print("æ­£åœ¨åŠ è½½ç­–ç•¥æ¨¡å‹...")
        policy = llava_pythia_act_policy(policy_config)
        print("ç­–ç•¥æ¨¡å‹åŠ è½½å®Œæˆ")
        print("æ­£åœ¨åˆå§‹åŒ–æœºå™¨äººç¯å¢ƒ...")
        deploy_env = FrankaROSEnvironment(left_cam_id=4, right_cam_id=10)
        # è®¾ç½®å…¨å±€å˜é‡
        global_deploy_env = deploy_env
        print("æœºå™¨äººç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")

        # å®‰å…¨åˆå§‹åŒ–ï¼šå‘é€åˆå§‹å®‰å…¨ä½ç½®
        print("æ‰§è¡Œå®‰å…¨åˆå§‹åŒ–...")
        deploy_env.send_safe_position()
        print("å®‰å…¨åˆå§‹åŒ–å®Œæˆ")

        eval_bc(policy, deploy_env, policy_config, save_episode=True, num_rollouts=1, raw_lang=raw_lang)
    except KeyboardInterrupt:
        print("ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        # æ‰§è¡Œç´§æ€¥åœæ­¢
        if global_deploy_env is not None:
            global_deploy_env.emergency_stop()
    except rospy.ROSInterruptException:
        print("ROSä¸­æ–­")
    except Exception as e:
        print(f"è¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ç¡®ä¿ROSèŠ‚ç‚¹æ­£ç¡®å…³é—­
        if not rospy.is_shutdown():
            rospy.signal_shutdown("ç¨‹åºæ‰§è¡Œå®Œæˆ")
        print("ç¨‹åºå·²é€€å‡º")